{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADED\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n",
      "torch.Size([1, 2, 710])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-556aaf2167ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sigmoid\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import gaussian\n",
    "\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    signal = signal - np.mean(signal)\n",
    "    return signal / np.max(np.abs(signal))\n",
    "\n",
    "def read_dataset(filename):\n",
    "    return pd.read_csv(filename, header = None)\n",
    "\n",
    "\n",
    "def check_labels(labs):\n",
    "    pos = -1\n",
    "    for i, elem in enumerate(labs):\n",
    "        if elem == 1:\n",
    "            pos = i\n",
    "    if abs(pos - len(labs)/2) <25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def build_labels(inputs1, inputs2, labels):\n",
    "    kernel = gaussian(21, 11)\n",
    "    inputs1 = normalize_signal(inputs1)\n",
    "    inputs2 = normalize_signal(inputs2)\n",
    "    res = np.convolve(labels, kernel, 'same')\n",
    "    return res[10:-10], inputs1[10:-10], inputs2[10:-10]\n",
    "\n",
    "\n",
    "\n",
    "def build_batch(inputs1, inputs2, labels):\n",
    "    n = 100\n",
    "    step = 5\n",
    "    data = []\n",
    "    lab = []\n",
    "    i = 100\n",
    "    while i < len(inputs1)-n:\n",
    "        data.append([np.asarray(inputs1[i:i+n]).astype(np.double), np.asarray(inputs2[i:i+n]).astype(np.double)])\n",
    "        # data.append(np.asarray(inputs1[i:i+n]).astype(np.double))\n",
    "        l = check_labels(labels[i:i+n])\n",
    "        lab.append(l)\n",
    "        # if l == 0:\n",
    "        #     plt.plot(range(n), inputs1[i:i+n])\n",
    "        #     plt.plot(range(n), inputs2[i:i+n])\n",
    "        #     plt.show()\n",
    "        i += step\n",
    "    ones = np.sum(lab)\n",
    "    final_data = []\n",
    "    final_lab = []\n",
    "    for i, elem in enumerate(data):\n",
    "        # print(lab[i])\n",
    "        if lab[i] == 0 and ones > 0:\n",
    "            final_data.append(elem)\n",
    "            final_lab.append(0)\n",
    "            ones -= 1\n",
    "        if lab[i] == 1:\n",
    "            final_data.append(elem)\n",
    "            final_lab.append(1)\n",
    "    return final_data, final_lab\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.c1 = nn.Conv1d(input_size, 64, kernel_size=63)#, padding=31, padding_mode='zeros')\n",
    "        self.c2 = nn.Conv1d(64, 128, kernel_size=11)#, padding=5, padding_mode='zeros')\n",
    "        self.c3 = nn.Conv1d(128, 1, kernel_size = 11)#, padding=5, padding_mode='zeros')\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "        d = torch.zeros([1,2,792])\n",
    "        d[0,:,41:751] = inputs\n",
    "        # d = inputs\n",
    "        c = self.c1(d)\n",
    "        p = F.relu(c)\n",
    "        c = self.c2(p)\n",
    "        p = F.relu(c)\n",
    "        c = self.c3(p)\n",
    "        \n",
    "        sigm = Sigmoid()\n",
    "        p = sigm(self.c3(p))\n",
    "        return p\n",
    "\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "batch_size = 5\n",
    "n_layers = 2\n",
    "seq_len = 1\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers=n_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "dataset = read_dataset(\"dataset_contact.csv\")\n",
    "print(\"DATASET LOADED\")\n",
    "data = np.asarray([])\n",
    "labels = np.asarray([])\n",
    "\n",
    "\n",
    "epoch = 1\n",
    "running_loss = 0.0\n",
    "hidden = None\n",
    "i = 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    i = 0\n",
    "    losses = []\n",
    "    steps = []\n",
    "    while i < dataset.shape[0]-3:\n",
    "\n",
    "        input1 = dataset.iloc[i]\n",
    "        input2 = dataset.iloc[i+1]\n",
    "        labels = dataset.iloc[i+2]\n",
    "        labels1, input1, input2 = build_labels(input1, input2, labels)\n",
    "\n",
    "        input_batch = [[input1, input2]]\n",
    "        output_batch = [labels1]\n",
    "        inputs = torch.from_numpy(np.asarray(input_batch)).float()\n",
    "        labels = torch.from_numpy(np.asarray(output_batch)).float()\n",
    "        print(np.shape(inputs))\n",
    "\n",
    "        res1 = rnn.forward(inputs)\n",
    "        to_plot = normalize_signal(res1.detach().numpy()[0][0])\n",
    "        to_plot2 = normalize_signal(input1)\n",
    "        # print(to_plot)\n",
    "        # plt.plot(range(len(to_plot2)), to_plot2)\n",
    "        # plt.plot(range(len(to_plot)), to_plot)\n",
    "        # plt.plot(range(len(labels1)), labels1)\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "        res = res1.squeeze()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(res, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        steps.append(i)\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                # print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "                # plt.plot(range(len(to_plot2)), to_plot2)\n",
    "                # plt.plot(range(len(to_plot)), to_plot)\n",
    "                # plt.plot(range(len(to_plot2)), to_plot2)\n",
    "                # plt.plot(range(len(labels1)), labels1)\n",
    "                # plt.legend()\n",
    "                # plt.show()\n",
    "\n",
    "        i += 3\n",
    "    plt.plot(steps, losses)\n",
    "    print(np.shape(steps))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rnn(inputs)\n",
    "print(np.shape(inputs))\n",
    "plt.plot(inputs[0][0].data.numpy())\n",
    "plt.plot(res[0][0].data.numpy())\n",
    "plt.plot(labels[0].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(input1)\n",
    "plt.plot(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
