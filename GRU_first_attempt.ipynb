{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): GRU(1, 30, num_layers=5, dropout=0.01)\n",
      "  (out): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "L1Loss()\n",
      "-----------------------\n",
      "training set parameters\n",
      "-----------------------\n",
      "286\n",
      "2\n",
      "50\n",
      "150\n",
      "-----------------------\n",
      "Epoch: 1/5............. Loss: 0.2741\n",
      "Epoch: 1/5............. Loss: 0.2011\n",
      "Epoch: 1/5............. Loss: 0.0144\n",
      "Epoch: 1/5............. Loss: 0.0373\n",
      "Epoch: 1/5............. Loss: 0.0283\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0203\n",
      "Epoch: 1/5............. Loss: 0.0238\n",
      "Epoch: 1/5............. Loss: 0.0128\n",
      "Epoch: 1/5............. Loss: 0.0369\n",
      "Epoch: 1/5............. Loss: 0.0375\n",
      "Epoch: 1/5............. Loss: 0.0178\n",
      "Epoch: 1/5............. Loss: 0.0381\n",
      "Epoch: 1/5............. Loss: 0.0483\n",
      "Epoch: 1/5............. Loss: 0.0361\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0379\n",
      "Epoch: 1/5............. Loss: 0.0480\n",
      "Epoch: 1/5............. Loss: 0.0471\n",
      "Epoch: 1/5............. Loss: 0.0343\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0346\n",
      "Epoch: 1/5............. Loss: 0.0482\n",
      "Epoch: 1/5............. Loss: 0.0456\n",
      "Epoch: 1/5............. Loss: 0.0280\n",
      "Epoch: 1/5............. Loss: 0.0117\n",
      "Epoch: 1/5............. Loss: 0.0213\n",
      "Epoch: 1/5............. Loss: 0.0175\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0138\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0178\n",
      "Epoch: 1/5............. Loss: 0.0195\n",
      "Epoch: 1/5............. Loss: 0.0145\n",
      "Epoch: 1/5............. Loss: 0.0141\n",
      "Epoch: 1/5............. Loss: 0.0183\n",
      "Epoch: 1/5............. Loss: 0.0140\n",
      "Epoch: 1/5............. Loss: 0.0138\n",
      "Epoch: 1/5............. Loss: 0.0169\n",
      "Epoch: 1/5............. Loss: 0.0121\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0154\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0135\n",
      "Epoch: 1/5............. Loss: 0.0169\n",
      "Epoch: 1/5............. Loss: 0.0123\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0135\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0127\n",
      "Epoch: 1/5............. Loss: 0.0140\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0134\n",
      "Epoch: 1/5............. Loss: 0.0162\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0103\n",
      "Epoch: 1/5............. Loss: 0.0140\n",
      "Epoch: 1/5............. Loss: 0.0144\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0082\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0158\n",
      "Epoch: 1/5............. Loss: 0.0132\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0139\n",
      "Epoch: 1/5............. Loss: 0.0111\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0138\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0121\n",
      "Epoch: 1/5............. Loss: 0.0106\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0137\n",
      "Epoch: 1/5............. Loss: 0.0111\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0129\n",
      "Epoch: 1/5............. Loss: 0.0093\n",
      "Epoch: 1/5............. Loss: 0.0130\n",
      "Epoch: 1/5............. Loss: 0.0129\n",
      "Epoch: 1/5............. Loss: 0.0112\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0104\n",
      "Epoch: 1/5............. Loss: 0.0126\n",
      "Epoch: 1/5............. Loss: 0.0132\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0098\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0122\n",
      "Epoch: 1/5............. Loss: 0.0132\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0143\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0107\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0124\n",
      "Epoch: 1/5............. Loss: 0.0117\n",
      "Epoch: 1/5............. Loss: 0.0103\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0123\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0130\n",
      "Epoch: 1/5............. Loss: 0.0093\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0122\n",
      "Epoch: 1/5............. Loss: 0.0094\n",
      "Epoch: 1/5............. Loss: 0.0103\n",
      "Epoch: 1/5............. Loss: 0.0121\n",
      "Epoch: 1/5............. Loss: 0.0093\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0128\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0104\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0101\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0094\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0122\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0096\n",
      "Epoch: 1/5............. Loss: 0.0124\n",
      "Epoch: 1/5............. Loss: 0.0085\n",
      "Epoch: 1/5............. Loss: 0.0111\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0107\n",
      "Epoch: 1/5............. Loss: 0.0096\n",
      "Epoch: 1/5............. Loss: 0.0117\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0111\n",
      "Epoch: 1/5............. Loss: 0.0119\n",
      "Epoch: 1/5............. Loss: 0.0089\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0121\n",
      "Epoch: 1/5............. Loss: 0.0098\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0129\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0092\n",
      "Epoch: 1/5............. Loss: 0.0128\n",
      "Epoch: 1/5............. Loss: 0.0089\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0123\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0101\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0127\n",
      "Epoch: 1/5............. Loss: 0.0091\n",
      "Epoch: 1/5............. Loss: 0.0099\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0094\n",
      "Epoch: 1/5............. Loss: 0.0099\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0086\n",
      "Epoch: 1/5............. Loss: 0.0104\n",
      "Epoch: 1/5............. Loss: 0.0121\n",
      "Epoch: 1/5............. Loss: 0.0072\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0107\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0085\n",
      "Epoch: 1/5............. Loss: 0.0103\n",
      "Epoch: 1/5............. Loss: 0.0127\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0093\n",
      "Epoch: 1/5............. Loss: 0.0106\n",
      "Epoch: 1/5............. Loss: 0.0081\n",
      "Epoch: 1/5............. Loss: 0.0116\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0107\n",
      "Epoch: 1/5............. Loss: 0.0090\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0084\n",
      "Epoch: 1/5............. Loss: 0.0106\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0105\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0083\n",
      "Epoch: 1/5............. Loss: 0.0105\n",
      "Epoch: 1/5............. Loss: 0.0132\n",
      "Epoch: 1/5............. Loss: 0.0112\n",
      "Epoch: 1/5............. Loss: 0.0084\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0088\n",
      "Epoch: 1/5............. Loss: 0.0119\n",
      "Epoch: 1/5............. Loss: 0.0117\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5............. Loss: 0.0073\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0114\n",
      "Epoch: 1/5............. Loss: 0.0103\n",
      "Epoch: 1/5............. Loss: 0.0092\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0084\n",
      "Epoch: 1/5............. Loss: 0.0105\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0105\n",
      "Epoch: 1/5............. Loss: 0.0098\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0087\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0098\n",
      "Epoch: 1/5............. Loss: 0.0082\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0094\n",
      "Epoch: 1/5............. Loss: 0.0078\n",
      "Epoch: 1/5............. Loss: 0.0096\n",
      "Epoch: 1/5............. Loss: 0.0079\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0125\n",
      "Epoch: 1/5............. Loss: 0.0099\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0097\n",
      "Epoch: 1/5............. Loss: 0.0101\n",
      "Epoch: 1/5............. Loss: 0.0099\n",
      "Epoch: 1/5............. Loss: 0.0106\n",
      "Epoch: 1/5............. Loss: 0.0105\n",
      "Epoch: 1/5............. Loss: 0.0090\n",
      "Epoch: 1/5............. Loss: 0.0098\n",
      "Epoch: 1/5............. Loss: 0.0090\n",
      "Epoch: 1/5............. Loss: 0.0117\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0106\n",
      "Epoch: 1/5............. Loss: 0.0089\n",
      "Epoch: 1/5............. Loss: 0.0090\n",
      "Epoch: 1/5............. Loss: 0.0080\n",
      "Epoch: 1/5............. Loss: 0.0111\n",
      "Epoch: 1/5............. Loss: 0.0120\n",
      "Epoch: 1/5............. Loss: 0.0086\n",
      "Epoch: 1/5............. Loss: 0.0110\n",
      "Epoch: 1/5............. Loss: 0.0122\n",
      "Epoch: 1/5............. Loss: 0.0113\n",
      "Epoch: 1/5............. Loss: 0.0091\n",
      "Epoch: 1/5............. Loss: 0.0099\n",
      "Epoch: 1/5............. Loss: 0.0075\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "Epoch: 1/5............. Loss: 0.0109\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0101\n",
      "Epoch: 1/5............. Loss: 0.0112\n",
      "Epoch: 1/5............. Loss: 0.0092\n",
      "Epoch: 1/5............. Loss: 0.0089\n",
      "Epoch: 1/5............. Loss: 0.0095\n",
      "Epoch: 1/5............. Loss: 0.0073\n",
      "Epoch: 1/5............. Loss: 0.0102\n",
      "Epoch: 1/5............. Loss: 0.0119\n",
      "Epoch: 1/5............. Loss: 0.0089\n",
      "Epoch: 1/5............. Loss: 0.0088\n",
      "Epoch: 1/5............. Loss: 0.0100\n",
      "Epoch: 1/5............. Loss: 0.0081\n",
      "Epoch: 1/5............. Loss: 0.0115\n",
      "Epoch: 1/5............. Loss: 0.0118\n",
      "Epoch: 1/5............. Loss: 0.0108\n",
      "-----------------------\n",
      "training set parameters\n",
      "-----------------------\n",
      "286\n",
      "2\n",
      "50\n",
      "150\n",
      "-----------------------\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0075\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0113\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0070\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0102\n",
      "Epoch: 2/5............. Loss: 0.0111\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0114\n",
      "Epoch: 2/5............. Loss: 0.0102\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0103\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0138\n",
      "Epoch: 2/5............. Loss: 0.0102\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0103\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0112\n",
      "Epoch: 2/5............. Loss: 0.0118\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0105\n",
      "Epoch: 2/5............. Loss: 0.0114\n",
      "Epoch: 2/5............. Loss: 0.0097\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0107\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0104\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0108\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0092\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0080\n",
      "Epoch: 2/5............. Loss: 0.0099\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0105\n",
      "Epoch: 2/5............. Loss: 0.0076\n",
      "Epoch: 2/5............. Loss: 0.0124\n",
      "Epoch: 2/5............. Loss: 0.0123\n",
      "Epoch: 2/5............. Loss: 0.0110\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0129\n",
      "Epoch: 2/5............. Loss: 0.0140\n",
      "Epoch: 2/5............. Loss: 0.0135\n",
      "Epoch: 2/5............. Loss: 0.0110\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0111\n",
      "Epoch: 2/5............. Loss: 0.0113\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0120\n",
      "Epoch: 2/5............. Loss: 0.0128\n",
      "Epoch: 2/5............. Loss: 0.0137\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0129\n",
      "Epoch: 2/5............. Loss: 0.0149\n",
      "Epoch: 2/5............. Loss: 0.0133\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0103\n",
      "Epoch: 2/5............. Loss: 0.0102\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0102\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0127\n",
      "Epoch: 2/5............. Loss: 0.0140\n",
      "Epoch: 2/5............. Loss: 0.0104\n",
      "Epoch: 2/5............. Loss: 0.0105\n",
      "Epoch: 2/5............. Loss: 0.0107\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0109\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0099\n",
      "Epoch: 2/5............. Loss: 0.0119\n",
      "Epoch: 2/5............. Loss: 0.0106\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0104\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0099\n",
      "Epoch: 2/5............. Loss: 0.0068\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0103\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0075\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0076\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0107\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0108\n",
      "Epoch: 2/5............. Loss: 0.0104\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0101\n",
      "Epoch: 2/5............. Loss: 0.0113\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0087\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0074\n",
      "Epoch: 2/5............. Loss: 0.0086\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0107\n",
      "Epoch: 2/5............. Loss: 0.0113\n",
      "Epoch: 2/5............. Loss: 0.0107\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0080\n",
      "Epoch: 2/5............. Loss: 0.0071\n",
      "Epoch: 2/5............. Loss: 0.0086\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0070\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0086\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0110\n",
      "Epoch: 2/5............. Loss: 0.0096\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0076\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5............. Loss: 0.0086\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0115\n",
      "Epoch: 2/5............. Loss: 0.0123\n",
      "Epoch: 2/5............. Loss: 0.0108\n",
      "Epoch: 2/5............. Loss: 0.0067\n",
      "Epoch: 2/5............. Loss: 0.0119\n",
      "Epoch: 2/5............. Loss: 0.0131\n",
      "Epoch: 2/5............. Loss: 0.0143\n",
      "Epoch: 2/5............. Loss: 0.0113\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0142\n",
      "Epoch: 2/5............. Loss: 0.0160\n",
      "Epoch: 2/5............. Loss: 0.0140\n",
      "Epoch: 2/5............. Loss: 0.0134\n",
      "Epoch: 2/5............. Loss: 0.0074\n",
      "Epoch: 2/5............. Loss: 0.0114\n",
      "Epoch: 2/5............. Loss: 0.0142\n",
      "Epoch: 2/5............. Loss: 0.0119\n",
      "Epoch: 2/5............. Loss: 0.0118\n",
      "Epoch: 2/5............. Loss: 0.0140\n",
      "Epoch: 2/5............. Loss: 0.0111\n",
      "Epoch: 2/5............. Loss: 0.0111\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0071\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0104\n",
      "Epoch: 2/5............. Loss: 0.0086\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0108\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0096\n",
      "Epoch: 2/5............. Loss: 0.0063\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0089\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0099\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0065\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0076\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0096\n",
      "Epoch: 2/5............. Loss: 0.0069\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0120\n",
      "Epoch: 2/5............. Loss: 0.0096\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0123\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0071\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0095\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0132\n",
      "Epoch: 2/5............. Loss: 0.0112\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0109\n",
      "Epoch: 2/5............. Loss: 0.0121\n",
      "Epoch: 2/5............. Loss: 0.0124\n",
      "Epoch: 2/5............. Loss: 0.0106\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0103\n",
      "Epoch: 2/5............. Loss: 0.0097\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0100\n",
      "Epoch: 2/5............. Loss: 0.0071\n",
      "Epoch: 2/5............. Loss: 0.0073\n",
      "Epoch: 2/5............. Loss: 0.0099\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0094\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0081\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0096\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0085\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0066\n",
      "Epoch: 2/5............. Loss: 0.0105\n",
      "Epoch: 2/5............. Loss: 0.0092\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0098\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0078\n",
      "Epoch: 2/5............. Loss: 0.0083\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0080\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0080\n",
      "Epoch: 2/5............. Loss: 0.0093\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0074\n",
      "Epoch: 2/5............. Loss: 0.0084\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "Epoch: 2/5............. Loss: 0.0072\n",
      "Epoch: 2/5............. Loss: 0.0091\n",
      "Epoch: 2/5............. Loss: 0.0087\n",
      "Epoch: 2/5............. Loss: 0.0079\n",
      "Epoch: 2/5............. Loss: 0.0090\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0087\n",
      "Epoch: 2/5............. Loss: 0.0077\n",
      "Epoch: 2/5............. Loss: 0.0087\n",
      "Epoch: 2/5............. Loss: 0.0080\n",
      "Epoch: 2/5............. Loss: 0.0082\n",
      "Epoch: 2/5............. Loss: 0.0088\n",
      "-----------------------\n",
      "training set parameters\n",
      "-----------------------\n",
      "286\n",
      "2\n",
      "50\n",
      "150\n",
      "-----------------------\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0092\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0102\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0098\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0106\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0099\n",
      "Epoch: 3/5............. Loss: 0.0100\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0109\n",
      "Epoch: 3/5............. Loss: 0.0102\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0067\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0093\n",
      "Epoch: 3/5............. Loss: 0.0098\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0103\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0093\n",
      "Epoch: 3/5............. Loss: 0.0099\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0098\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0105\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0092\n",
      "Epoch: 3/5............. Loss: 0.0107\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5............. Loss: 0.0103\n",
      "Epoch: 3/5............. Loss: 0.0098\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0093\n",
      "Epoch: 3/5............. Loss: 0.0106\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0112\n",
      "Epoch: 3/5............. Loss: 0.0130\n",
      "Epoch: 3/5............. Loss: 0.0119\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0093\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0095\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0108\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0096\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0093\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0071\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0069\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0072\n",
      "Epoch: 3/5............. Loss: 0.0095\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0067\n",
      "Epoch: 3/5............. Loss: 0.0092\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0068\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0066\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0104\n",
      "Epoch: 3/5............. Loss: 0.0106\n",
      "Epoch: 3/5............. Loss: 0.0104\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0098\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0096\n",
      "Epoch: 3/5............. Loss: 0.0108\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0095\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0100\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0092\n",
      "Epoch: 3/5............. Loss: 0.0074\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0071\n",
      "Epoch: 3/5............. Loss: 0.0071\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0094\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0105\n",
      "Epoch: 3/5............. Loss: 0.0106\n",
      "Epoch: 3/5............. Loss: 0.0103\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0070\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0072\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0075\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0100\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0110\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0092\n",
      "Epoch: 3/5............. Loss: 0.0076\n",
      "Epoch: 3/5............. Loss: 0.0083\n",
      "Epoch: 3/5............. Loss: 0.0096\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0099\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0122\n",
      "Epoch: 3/5............. Loss: 0.0130\n",
      "Epoch: 3/5............. Loss: 0.0131\n",
      "Epoch: 3/5............. Loss: 0.0102\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0091\n",
      "Epoch: 3/5............. Loss: 0.0096\n",
      "Epoch: 3/5............. Loss: 0.0070\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0079\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0095\n",
      "Epoch: 3/5............. Loss: 0.0082\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0090\n",
      "Epoch: 3/5............. Loss: 0.0088\n",
      "Epoch: 3/5............. Loss: 0.0097\n",
      "Epoch: 3/5............. Loss: 0.0087\n",
      "Epoch: 3/5............. Loss: 0.0084\n",
      "Epoch: 3/5............. Loss: 0.0086\n",
      "Epoch: 3/5............. Loss: 0.0080\n",
      "Epoch: 3/5............. Loss: 0.0085\n",
      "Epoch: 3/5............. Loss: 0.0081\n",
      "Epoch: 3/5............. Loss: 0.0089\n",
      "Epoch: 3/5............. Loss: 0.0077\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "Epoch: 3/5............. Loss: 0.0078\n",
      "Epoch: 3/5............. Loss: 0.0073\n",
      "-----------------------\n",
      "training set parameters\n",
      "-----------------------\n",
      "286\n",
      "2\n",
      "50\n",
      "150\n",
      "-----------------------\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0099\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0111\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0084\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0072\n",
      "Epoch: 4/5............. Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0075\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0069\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0073\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0075\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0064\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0109\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0086\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0098\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0098\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0103\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0086\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0104\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0075\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0108\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0084\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0086\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0109\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0105\n",
      "Epoch: 4/5............. Loss: 0.0103\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0109\n",
      "Epoch: 4/5............. Loss: 0.0086\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0114\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0087\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0073\n",
      "Epoch: 4/5............. Loss: 0.0072\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0062\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0103\n",
      "Epoch: 4/5............. Loss: 0.0114\n",
      "Epoch: 4/5............. Loss: 0.0118\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0111\n",
      "Epoch: 4/5............. Loss: 0.0116\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0067\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0106\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0119\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0106\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0103\n",
      "Epoch: 4/5............. Loss: 0.0102\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0104\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0105\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0111\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0071\n",
      "Epoch: 4/5............. Loss: 0.0070\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0106\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0108\n",
      "Epoch: 4/5............. Loss: 0.0120\n",
      "Epoch: 4/5............. Loss: 0.0106\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0070\n",
      "Epoch: 4/5............. Loss: 0.0087\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0073\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0081\n",
      "Epoch: 4/5............. Loss: 0.0098\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0067\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0087\n",
      "Epoch: 4/5............. Loss: 0.0069\n",
      "Epoch: 4/5............. Loss: 0.0093\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0084\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0087\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0110\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0099\n",
      "Epoch: 4/5............. Loss: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5............. Loss: 0.0107\n",
      "Epoch: 4/5............. Loss: 0.0103\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0108\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0105\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0097\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0082\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0087\n",
      "Epoch: 4/5............. Loss: 0.0100\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0084\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0096\n",
      "Epoch: 4/5............. Loss: 0.0079\n",
      "Epoch: 4/5............. Loss: 0.0088\n",
      "Epoch: 4/5............. Loss: 0.0091\n",
      "Epoch: 4/5............. Loss: 0.0083\n",
      "Epoch: 4/5............. Loss: 0.0094\n",
      "Epoch: 4/5............. Loss: 0.0095\n",
      "Epoch: 4/5............. Loss: 0.0101\n",
      "Epoch: 4/5............. Loss: 0.0080\n",
      "Epoch: 4/5............. Loss: 0.0086\n",
      "Epoch: 4/5............. Loss: 0.0076\n",
      "Epoch: 4/5............. Loss: 0.0099\n",
      "Epoch: 4/5............. Loss: 0.0110\n",
      "Epoch: 4/5............. Loss: 0.0092\n",
      "Epoch: 4/5............. Loss: 0.0078\n",
      "Epoch: 4/5............. Loss: 0.0107\n",
      "Epoch: 4/5............. Loss: 0.0130\n",
      "Epoch: 4/5............. Loss: 0.0115\n",
      "Epoch: 4/5............. Loss: 0.0107\n",
      "Epoch: 4/5............. Loss: 0.0074\n",
      "Epoch: 4/5............. Loss: 0.0089\n",
      "Epoch: 4/5............. Loss: 0.0085\n",
      "Epoch: 4/5............. Loss: 0.0077\n",
      "Epoch: 4/5............. Loss: 0.0090\n",
      "Epoch: 4/5............. Loss: 0.0072\n",
      "-----------------------\n",
      "training set parameters\n",
      "-----------------------\n",
      "286\n",
      "2\n",
      "50\n",
      "150\n",
      "-----------------------\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0099\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0098\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0102\n",
      "Epoch: 5/5............. Loss: 0.0119\n",
      "Epoch: 5/5............. Loss: 0.0117\n",
      "Epoch: 5/5............. Loss: 0.0104\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0109\n",
      "Epoch: 5/5............. Loss: 0.0131\n",
      "Epoch: 5/5............. Loss: 0.0130\n",
      "Epoch: 5/5............. Loss: 0.0125\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0113\n",
      "Epoch: 5/5............. Loss: 0.0122\n",
      "Epoch: 5/5............. Loss: 0.0104\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0099\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0102\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0069\n",
      "Epoch: 5/5............. Loss: 0.0091\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0069\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0070\n",
      "Epoch: 5/5............. Loss: 0.0102\n",
      "Epoch: 5/5............. Loss: 0.0102\n",
      "Epoch: 5/5............. Loss: 0.0100\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0073\n",
      "Epoch: 5/5............. Loss: 0.0103\n",
      "Epoch: 5/5............. Loss: 0.0099\n",
      "Epoch: 5/5............. Loss: 0.0096\n",
      "Epoch: 5/5............. Loss: 0.0095\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0099\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0091\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0073\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0069\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0065\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0096\n",
      "Epoch: 5/5............. Loss: 0.0110\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0100\n",
      "Epoch: 5/5............. Loss: 0.0097\n",
      "Epoch: 5/5............. Loss: 0.0119\n",
      "Epoch: 5/5............. Loss: 0.0097\n",
      "Epoch: 5/5............. Loss: 0.0073\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0071\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0102\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0095\n",
      "Epoch: 5/5............. Loss: 0.0065\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0073\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0064\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0069\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0091\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0104\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0070\n",
      "Epoch: 5/5............. Loss: 0.0111\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0111\n",
      "Epoch: 5/5............. Loss: 0.0095\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0103\n",
      "Epoch: 5/5............. Loss: 0.0127\n",
      "Epoch: 5/5............. Loss: 0.0113\n",
      "Epoch: 5/5............. Loss: 0.0095\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0095\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0070\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0086\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0107\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0063\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0064\n",
      "Epoch: 5/5............. Loss: 0.0101\n",
      "Epoch: 5/5............. Loss: 0.0103\n",
      "Epoch: 5/5............. Loss: 0.0103\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0105\n",
      "Epoch: 5/5............. Loss: 0.0116\n",
      "Epoch: 5/5............. Loss: 0.0089\n",
      "Epoch: 5/5............. Loss: 0.0093\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0070\n",
      "Epoch: 5/5............. Loss: 0.0092\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0082\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0076\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0081\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0075\n",
      "Epoch: 5/5............. Loss: 0.0085\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0072\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0098\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0084\n",
      "Epoch: 5/5............. Loss: 0.0083\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0079\n",
      "Epoch: 5/5............. Loss: 0.0071\n",
      "Epoch: 5/5............. Loss: 0.0087\n",
      "Epoch: 5/5............. Loss: 0.0074\n",
      "Epoch: 5/5............. Loss: 0.0088\n",
      "Epoch: 5/5............. Loss: 0.0078\n",
      "Epoch: 5/5............. Loss: 0.0080\n",
      "Epoch: 5/5............. Loss: 0.0071\n",
      "Epoch: 5/5............. Loss: 0.0090\n",
      "Epoch: 5/5............. Loss: 0.0094\n",
      "Epoch: 5/5............. Loss: 0.0077\n",
      "Epoch: 5/5............. Loss: 0.0096\n",
      "outputs torch.Size([1, 50, 150])\n",
      "hidden torch.Size([5, 50, 30])\n"
     ]
    }
   ],
   "source": [
    "from dataset_io import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sigmoid\n",
    "\n",
    "#===========================================\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, n_layers, dropout=0.01)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        batch_size = inputs.size(1)\n",
    "        \n",
    "        # Turn (seq_len x batch_size x input_size) into (batch_size x input_size x seq_len) for CNN\n",
    "        # inputs = inputs.transpose(0, 1)\n",
    "\n",
    "        # Run through Conv1d and Pool1d layers\n",
    "        p = inputs\n",
    "\n",
    "        # Turn (batch_size x hidden_size x seq_len) back into (seq_len x batch_size x hidden_size) for RNN\n",
    "        p = p.transpose(0,2)\n",
    "        \n",
    "        p = torch.tanh(p)\n",
    "        output, hidden = self.rnn(p, hidden)\n",
    "        conv_seq_len = output.size(0)\n",
    "        output = output.view(conv_seq_len * batch_size, self.hidden_size) # Treating (conv_seq_len x batch_size) as batch_size for linear layer\n",
    "        output = torch.tanh(self.out(output))\n",
    "        output = output.view(conv_seq_len, -1, self.output_size)\n",
    "        output = output.transpose(0,2)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "#===================================================================\n",
    "    \n",
    "input_size = 1\n",
    "hidden_size = 30\n",
    "output_size = 1\n",
    "batch_size = 50\n",
    "n_layers = 5\n",
    "seq_len = 150\n",
    "n_epochs = 5\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers=n_layers)\n",
    "print(rnn)\n",
    "rnn.to(torch.device(\"cpu\"))\n",
    "\n",
    "criterion = nn.L1Loss()                          #?????????????????????????????????\n",
    "print(criterion)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "hidden = rnn.init_hidden(batch_size)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    signals = read_contact_dataset(CONTACT_DATASET_NAME)\n",
    "    TrS, TsS = GRU_get_training_set(signals, 150)\n",
    "    training_set = parse_set2(TrS, batch_size)\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('training set parameters')\n",
    "    print('-----------------------')\n",
    "    print(len(training_set))\n",
    "    print(len(training_set[0]))\n",
    "    print(len(training_set[0][0]))\n",
    "    print(len(training_set[0][0][0]))\n",
    "    print('-----------------------')\n",
    "    \n",
    "    for (batch_in, batch_tag) in training_set:\n",
    "        batch_in /= np.max(batch_in)\n",
    "        batch_tag /= np.max(batch_tag)\n",
    "        inputs = Variable(torch.Tensor([batch_in]))\n",
    "        targets = Variable(torch.Tensor([batch_tag]))\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        inputs.to(torch.device(\"cpu\"))\n",
    "        outputs, hidden = rnn(inputs,None)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "        if epoch%1 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch+1, n_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "\n",
    "outputs, hidden = rnn(inputs, None)\n",
    "print('outputs', outputs.size()) # conv_seq_len x batch_size x output_size\n",
    "print('hidden', hidden.size()) # n_layers x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0006, 0.0006,\n",
      "          0.0007, 0.0006, 0.0006, 0.0006, 0.0007, 0.0007, 0.0006, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
      "          0.0006, 0.0007, 0.0007, 0.0006, 0.0007, 0.0007, 0.0006, 0.0006,\n",
      "          0.0006, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "          0.0007, 0.0007, 0.0006, 0.0006, 0.0006, 0.0007, 0.0005, 0.0006,\n",
      "          0.0007, 0.0006, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007,\n",
      "          0.0007, 0.0007, 0.0006, 0.0007, 0.0007, 0.0006, 0.0006, 0.0006,\n",
      "          0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "          0.0007, 0.0007, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0006,\n",
      "          0.0007, 0.0007, 0.0007, 0.0007, 0.0006, 0.0007, 0.0007, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0007,\n",
      "          0.0007, 0.0006, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "          0.0006, 0.0006, 0.0007, 0.0006, 0.0007, 0.0007, 0.0007, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0007, 0.0006, 0.0006, 0.0006, 0.0007,\n",
      "          0.0006, 0.0007, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0007,\n",
      "          0.0007, 0.0007, 0.0007, 0.0006, 0.0006, 0.0007]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "[0.00060965 0.00067733 0.00069865 0.00068198 0.00066157 0.0006523\n",
      " 0.00064831 0.00064825 0.00065153 0.00064962 0.00064901 0.0006476\n",
      " 0.0006536  0.00065748 0.00063595 0.00068662 0.00066797 0.00065831\n",
      " 0.00065777 0.00066278 0.00065446 0.00065396 0.00065403 0.000655\n",
      " 0.00065389 0.0006539  0.00065369 0.00065326 0.00065291 0.0006524\n",
      " 0.00065171 0.0006513  0.00064604 0.00065173 0.00065465 0.00064898\n",
      " 0.00065795 0.00065349 0.00062104 0.0006416  0.0006324  0.00066572\n",
      " 0.00062922 0.00064206 0.00064941 0.00064584 0.00062952 0.0006172\n",
      " 0.00066829 0.00068262 0.00063327 0.00064509 0.00064529 0.00065572\n",
      " 0.00054971 0.00064758 0.00065224 0.00064199 0.00066123 0.00065975\n",
      " 0.00065719 0.00065582 0.00065497 0.00065416 0.00065516 0.00065402\n",
      " 0.00064644 0.00065146 0.00065261 0.00064983 0.00064767 0.00064565\n",
      " 0.00064431 0.00064345 0.00064377 0.00064399 0.00064444 0.00064259\n",
      " 0.00064208 0.0006174  0.0006764  0.000672   0.00065561 0.0006465\n",
      " 0.00064361 0.00059359 0.00064969 0.00066839 0.0006946  0.00065895\n",
      " 0.00065535 0.00065424 0.0006527  0.00065469 0.0006546  0.00064147\n",
      " 0.00066029 0.00065867 0.00065705 0.00065561 0.00063721 0.0006631\n",
      " 0.00066003 0.00065789 0.00065291 0.00065113 0.0006758  0.00064127\n",
      " 0.00064435 0.00064131 0.0006223  0.00067386 0.00065854 0.00063652\n",
      " 0.00065432 0.00064821 0.00064556 0.00064441 0.00064479 0.00064591\n",
      " 0.00064113 0.00062907 0.00065812 0.00062839 0.0006698  0.00066977\n",
      " 0.00066313 0.0006551  0.0006515  0.00065033 0.00065202 0.00066098\n",
      " 0.0006267  0.00064788 0.00064673 0.00065507 0.00063971 0.00066416\n",
      " 0.00064613 0.00063175 0.00063229 0.00063911 0.00062558 0.00067637\n",
      " 0.00065477 0.00065379 0.00065118 0.00064804 0.00064696 0.00067536]\n",
      "(1, 1, 150)\n"
     ]
    }
   ],
   "source": [
    "out = rnn(torch.Tensor([[TrS[1][0]]]), None)\n",
    "print(out[0])\n",
    "out1 = out[0]\n",
    "out1 = out1.data.numpy()\n",
    "print(out1[0][0])\n",
    "print(out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xe510cc0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y = np.asarray([TsS[0][1],out])\n",
    "y = TrS[0][1]\n",
    "# print(len(TsS[0][0]))\n",
    "plt.plot(range(150), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1070b828>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(150)\n",
    "y = [TrS[1][1]/1000, out1[0][0]]\n",
    "plt.plot(x,y[0])\n",
    "plt.plot(x,y[1])\n",
    "# plt.plot(x, TsS[0][0]/1380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
